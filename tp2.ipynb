{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Portuguese POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_train = 'data/macmorpho-train.txt'\n",
    "file_test = 'data/macmorpho-test.txt'\n",
    "file_val = 'data/macmorpho-dev.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing(fname, train=False):\n",
    "    with open(fname, 'r') as text:\n",
    "        lines = text.readlines()\n",
    "\n",
    "    sentences_words = []\n",
    "    sentences_tags = []\n",
    "    for l in lines:\n",
    "        sentence = l.replace('\\n', '').split(' ')\n",
    "        words_token = []\n",
    "        tags_token = []\n",
    "        for s in sentence:\n",
    "            word_tag = s.split('_')\n",
    "            words_token.append(word_tag[0])\n",
    "            tags_token.append(word_tag[1])\n",
    "        sentences_words.append(words_token)\n",
    "        sentences_tags.append(tags_token)\n",
    "        \n",
    "    if train:\n",
    "        return create_dict_to_numbers(sentences_words, sentences_tags)\n",
    "    \n",
    "    return sentences_words, sentences_tags\n",
    "\n",
    "def create_dict_to_numbers(sentences_words, sentences_tags):\n",
    "    word2number = {}\n",
    "    tag2number = {}\n",
    "    \n",
    "    i = 2\n",
    "    for s in sentences_words:\n",
    "        for word in s:\n",
    "            if word.lower() not in word2number.keys():\n",
    "                word2number[word.lower()] = i\n",
    "                i+=1\n",
    "    word2number['--padding--'] = 0\n",
    "    word2number['--not-exist--'] = 1\n",
    "    \n",
    "    i = 1\n",
    "    for s in sentences_tags:\n",
    "        for tag in s:\n",
    "            if tag not in tag2number.keys():\n",
    "                tag2number[tag] = i\n",
    "                i+=1\n",
    "    tag2number['--padding--'] = 0\n",
    "    \n",
    "    return sentences_words, sentences_tags, word2number, tag2number\n",
    "\n",
    "def one_hot_encoding_tags(sentences_tags, tag2number):\n",
    "    sentences_Y = []\n",
    "    \n",
    "    for s in sentences_tags:\n",
    "        s_categories = []\n",
    "        for t in s:\n",
    "            tags = np.zeros(len(tag2number)) \n",
    "            tags[tag2number[t]] = 1\n",
    "            s_categories.append(tags)\n",
    "        sentences_Y.append(s_categories)\n",
    "    \n",
    "    return sentences_Y\n",
    "\n",
    "def convert_to_numbers(sentences_words, sentences_tags, word2number, tag2number):\n",
    "    sentences_X = []\n",
    "    \n",
    "    for s in sentences_words:\n",
    "        aux_sent = []\n",
    "        for w in s:\n",
    "            try:\n",
    "                aux_sent.append(word2number[w.lower()])\n",
    "            except:\n",
    "                aux_sent.append(word2number['--not-exist--'])\n",
    "        sentences_X.append(aux_sent)\n",
    "    \n",
    "    return sentences_X, one_hot_encoding_tags(sentences_tags, tag2number)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End Pre-Processing Train\n",
      "End Pre-Processing Test\n",
      "End Pre-Processing Val\n"
     ]
    }
   ],
   "source": [
    "train_words, train_tags, word2number, tag2number = pre_processing(file_train, train=True)\n",
    "train_X, train_Y = convert_to_numbers(train_words, train_tags, word2number, tag2number)\n",
    "\n",
    "print('End Pre-Processing Train')\n",
    "test_words, test_tags = pre_processing(file_test)\n",
    "test_X, test_Y = convert_to_numbers(test_words, test_tags, word2number, tag2number)\n",
    "print('End Pre-Processing Test')\n",
    "val_words, val_tags = pre_processing(file_val)\n",
    "val_X, val_Y = convert_to_numbers(val_words, val_tags, word2number, tag2number)\n",
    "print('End Pre-Processing Val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190\n"
     ]
    }
   ],
   "source": [
    "MAX_LENGTH = len(max(train_X, key=len))\n",
    "print(MAX_LENGTH)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding_sequences(sequences_words, sequences_tags, MAX_LENGTH):\n",
    "    sequences_words = pad_sequences(sequences_words, maxlen=MAX_LENGTH, padding='post')\n",
    "    sequences_tags = pad_sequences(sequences_tags, maxlen=MAX_LENGTH, padding='post')\n",
    "    for s in sequences_tags:\n",
    "        for t in s:\n",
    "            if np.all((t == 0)):\n",
    "                t[0] = 1\n",
    "    return sequences_words, sequences_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_Y = padding_sequences(train_X, train_Y, MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X, test_Y = padding_sequences(test_X, test_Y, MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/isadorasalles/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 190, 128)          6046464   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 190, 512)          788480    \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 190, 27)           13851     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 190, 27)           0         \n",
      "=================================================================\n",
      "Total params: 6,848,795\n",
      "Trainable params: 6,848,795\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, InputLayer, Bidirectional, TimeDistributed, Embedding, Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "\n",
    "def single(INTERESTING_CLASS_ID):\n",
    "    def single_class_accuracy(y_true, y_pred):\n",
    "        class_id_true = K.argmax(y_true, axis=-1)\n",
    "        class_id_preds = K.argmax(y_pred, axis=-1)\n",
    "        # Replace class_id_preds with class_id_true for recall here\n",
    "        accuracy_mask = K.cast(K.equal(class_id_preds, INTERESTING_CLASS_ID), 'int32')\n",
    "        class_acc_tensor = K.cast(K.equal(class_id_true, class_id_preds), 'int32') * accuracy_mask\n",
    "        class_acc = K.sum(class_acc_tensor) / K.maximum(K.sum(accuracy_mask), 1)\n",
    "        return class_acc\n",
    "    return single_class_accuracy\n",
    "\n",
    " \n",
    "\n",
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=(MAX_LENGTH, )))\n",
    "model.add(Embedding(len(word2number), 128))\n",
    "model.add(Bidirectional(LSTM(256, return_sequences=True)))\n",
    "model.add(TimeDistributed(Dense(len(tag2number))))\n",
    "model.add(Activation('softmax'))\n",
    " \n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer ='rmsprop',\n",
    "              metrics=['accuracy', single(0), single(1), single(2), single(3), single(4), single(5), single(6),\n",
    "                      single(7), single(8), single(9), single(10), single(11), single(12), single(13),\n",
    "                      single(14), single(15), single(16), single(17), single(18), single(19), single(20),\n",
    "                      single(21), single(22), single(23), single(24), single(25), single(26)])\n",
    " \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/isadorasalles/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/isadorasalles/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Epoch 1/1\n",
      "37948/37948 [==============================] - 470s 12ms/step - loss: 0.1552 - acc: 0.9572 - single_class_accuracy: 0.9900 - single_class_accuracy_1: 0.5633 - single_class_accuracy_2: 0.5130 - single_class_accuracy_3: 0.6692 - single_class_accuracy_4: 0.3958 - single_class_accuracy_5: 0.4622 - single_class_accuracy_6: 0.6188 - single_class_accuracy_7: 0.4534 - single_class_accuracy_8: 0.8019 - single_class_accuracy_9: 0.4789 - single_class_accuracy_10: 0.4403 - single_class_accuracy_11: 0.3665 - single_class_accuracy_12: 0.6006 - single_class_accuracy_13: 0.6282 - single_class_accuracy_14: 0.3988 - single_class_accuracy_15: 0.3197 - single_class_accuracy_16: 0.4715 - single_class_accuracy_17: 0.4609 - single_class_accuracy_18: 0.2256 - single_class_accuracy_19: 0.3104 - single_class_accuracy_20: 0.2844 - single_class_accuracy_21: 0.0000e+00 - single_class_accuracy_22: 0.1334 - single_class_accuracy_23: 0.0000e+00 - single_class_accuracy_24: 0.0067 - single_class_accuracy_25: 0.0000e+00 - single_class_accuracy_26: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ffad0e4f8d0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_X, train_Y, batch_size=128, epochs=1, validation_split=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9987/9987 [==============================] - 48s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(test_X, test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.03487198840991995,\n",
       " 0.9896428521252184,\n",
       " 1.0,\n",
       " 0.868517440912023,\n",
       " 0.8502589772370378,\n",
       " 0.9122992847331929,\n",
       " 0.3732852708521077,\n",
       " 0.7632375010398152,\n",
       " 0.9423193529833024,\n",
       " 0.7505708996938794,\n",
       " 0.9995071591144277,\n",
       " 0.942215660694664,\n",
       " 0.8181098920660352,\n",
       " 0.7470542458365096,\n",
       " 0.9779134634227807,\n",
       " 0.9439283291330504,\n",
       " 0.5851208868716193,\n",
       " 0.7197817124177733,\n",
       " 0.800885547415469,\n",
       " 0.9477818363473742,\n",
       " 0.48436300524014547,\n",
       " 0.7583916233961293,\n",
       " 0.7244543447607432,\n",
       " 0.0,\n",
       " 0.15379993992189847,\n",
       " 0.0,\n",
       " 0.01922499249023731,\n",
       " 0.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 98.96428521252184\n"
     ]
    }
   ],
   "source": [
    "print(f\"{model.metrics_names[1]}: {scores[1] * 100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.019485465943363096, 0.08829794530188391]\n"
     ]
    }
   ],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
