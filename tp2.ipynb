{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Portuguese POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/isadorasalles/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/isadorasalles/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/isadorasalles/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/isadorasalles/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/isadorasalles/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/isadorasalles/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, InputLayer, Bidirectional, TimeDistributed, Embedding, Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.metrics import Precision\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_train = 'data/macmorpho-train.txt'\n",
    "file_test = 'data/macmorpho-test.txt'\n",
    "file_val = 'data/macmorpho-dev.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing(fname, train=False):\n",
    "    with open(fname, 'r') as text:\n",
    "        lines = text.readlines()\n",
    "\n",
    "    sentences_words = []\n",
    "    sentences_tags = []\n",
    "    for l in lines:\n",
    "        sentence = l.replace('\\n', '').split(' ')\n",
    "        words_token = []\n",
    "        tags_token = []\n",
    "        for s in sentence:\n",
    "            word_tag = s.split('_')\n",
    "            words_token.append(word_tag[0])\n",
    "            tags_token.append(word_tag[1])\n",
    "        sentences_words.append(words_token)\n",
    "        sentences_tags.append(tags_token)\n",
    "        \n",
    "    if train:\n",
    "        return create_dict_to_numbers(sentences_words, sentences_tags)\n",
    "    \n",
    "    return sentences_words, sentences_tags\n",
    "\n",
    "def create_dict_to_numbers(sentences_words, sentences_tags):\n",
    "    word2number = {}\n",
    "    tag2number = {}\n",
    "    \n",
    "    i = 2\n",
    "    for s in sentences_words:\n",
    "        for word in s:\n",
    "            if word.lower() not in word2number.keys():\n",
    "                word2number[word.lower()] = i\n",
    "                i+=1\n",
    "    word2number['--padding--'] = 0\n",
    "    word2number['--not-exist--'] = 1\n",
    "    \n",
    "    i = 1\n",
    "    for s in sentences_tags:\n",
    "        for tag in s:\n",
    "            if tag not in tag2number.keys():\n",
    "                tag2number[tag] = i\n",
    "                i+=1\n",
    "    tag2number['--padding--'] = 0\n",
    "    \n",
    "    return sentences_words, sentences_tags, word2number, tag2number\n",
    "\n",
    "def convert_to_numbers(sentences_words, sentences_tags, word2number, tag2number):\n",
    "    sentences_X, sentences_Y = [], []\n",
    "    \n",
    "    for s in sentences_words:\n",
    "        aux_sent = []\n",
    "        for w in s:\n",
    "            try:\n",
    "                aux_sent.append(word2number[w.lower()])\n",
    "            except:\n",
    "                aux_sent.append(word2number['--not-exist--'])\n",
    "        sentences_X.append(aux_sent)\n",
    "        \n",
    "    for s in sentences_tags:\n",
    "        sentences_Y.append([tag2number[t] for t in s])\n",
    "    \n",
    "    return sentences_X, sentences_Y\n",
    "\n",
    "def one_hot_encoding_tags(sentences_tags, tag2number):\n",
    "    sentences_Y = []\n",
    "    \n",
    "    for s in sentences_tags:\n",
    "        s_categories = []\n",
    "        for t in s:\n",
    "            tags = np.zeros(len(tag2number)) \n",
    "            tags[t] = 1\n",
    "            s_categories.append(tags)\n",
    "        sentences_Y.append(s_categories)\n",
    "    \n",
    "    return sentences_Y\n",
    "\n",
    "def padding_sequences(sequences_words, sequences_tags, MAX_LENGTH, tag2number):\n",
    "    sequences_words = pad_sequences(sequences_words, maxlen=MAX_LENGTH, padding='post')\n",
    "    sequences_tags = pad_sequences(sequences_tags, maxlen=MAX_LENGTH, padding='post')\n",
    "#     for s in sequences_tags:\n",
    "#         for t in s:\n",
    "#             if np.all((t == 0)):\n",
    "#                 t[0] = 1\n",
    "    sequences_tags = one_hot_encoding_tags(sequences_tags, tag2number)\n",
    "    return sequences_words, sequences_tags\n",
    "\n",
    "\n",
    "def ignore_pad_acc(to_ignore=0):\n",
    "    ## ignorar a classe 0, referente ao padding, para computar a acur√°cia total\n",
    "    def ignore_padding_accuracy(y_true, y_pred):\n",
    "        y_true_ids = K.argmax(y_true, axis=-1)\n",
    "        y_pred_ids = K.argmax(y_pred, axis=-1)\n",
    " \n",
    "        padding_mask = K.cast(K.not_equal(y_pred_ids, to_ignore), 'int32')\n",
    "        matches_without_padding = K.cast(K.equal(y_true_ids, y_pred_ids), 'int32') * padding_mask\n",
    "        accuracy = K.sum(matches_without_padding) /  K.maximum(K.sum(padding_mask), 1)\n",
    "        \n",
    "        return accuracy\n",
    "    \n",
    "    return ignore_padding_accuracy\n",
    "\n",
    "def precision(id_of_interest):\n",
    "    \n",
    "    def class_precision(y_true, y_pred):\n",
    "        y_true_ids = K.argmax(y_true, axis=-1)\n",
    "        y_preds_ids = K.argmax(y_pred, axis=-1)\n",
    "        \n",
    "        retrieved_mask = K.cast(K.equal(y_preds_ids, id_of_interest), 'int32') # tp+fp\n",
    "        class_true_positive = K.cast(K.equal(y_true_ids, y_preds_ids), 'int32') * retrieved_mask # tp\n",
    "        class_prec = K.sum(class_true_positive) /  K.maximum(K.sum(retrieved_mask), 1) # tp / tp+fp\n",
    "        \n",
    "        return class_prec\n",
    "    \n",
    "    return class_precision\n",
    "\n",
    "def recall(id_of_interest):\n",
    "    \n",
    "    def class_recall(y_true, y_pred):\n",
    "        y_true_ids = K.argmax(y_true, axis=-1)\n",
    "        y_preds_ids = K.argmax(y_pred, axis=-1)\n",
    "        \n",
    "        relevant_mask = K.cast(K.equal(y_true_ids, id_of_interest), 'int32') # tp+fn\n",
    "        class_true_positive = K.cast(K.equal(y_true_ids, y_preds_ids), 'int32') * relevant_mask # tp\n",
    "        class_rec = K.sum(class_true_positive) /  K.maximum(K.sum(relevant_mask), 1) # tp / tp+fn\n",
    "        \n",
    "        return class_rec\n",
    "    \n",
    "    return class_recall\n",
    "\n",
    "\n",
    "def accuracy(id_of_interest):\n",
    "    \n",
    "    def class_accuracy(y_true, y_pred):\n",
    "        y_true_ids = K.argmax(y_true, axis=-1)\n",
    "        y_preds_ids = K.argmax(y_pred, axis=-1)\n",
    "\n",
    "        positive_mask = K.cast(K.equal(y_preds_ids, id_of_interest), 'int32') # tp+fp\n",
    "        class_true_positive = K.cast(K.equal(y_true_ids, y_preds_ids), 'int32') * positive_mask # tp\n",
    "        \n",
    "        negative_mask = K.cast(K.not_equal(y_preds_ids, id_of_interest), 'int32') # tn+fn\n",
    "        class_true_negative = K.cast(K.equal(y_true_ids, y_preds_ids), 'int32') * negative_mask # tn\n",
    "        \n",
    "        tp_sum_tn = K.sum(class_true_positive) + K.sum(class_true_negative)\n",
    "        sum_all =  K.maximum(K.sum(positive_mask) + K.sum(negative_mask), 1)\n",
    "        \n",
    "        return tp_sum_tn / sum_all\n",
    "    \n",
    "    return class_accuracy\n",
    "\n",
    "def create_model(MAX_LENGTH, tag2number, word2number):\n",
    "    model = Sequential()\n",
    "    model.add(InputLayer(input_shape=(MAX_LENGTH, )))\n",
    "    model.add(Embedding(len(word2number), 128))\n",
    "    model.add(Bidirectional(LSTM(256, return_sequences=True)))\n",
    "    model.add(TimeDistributed(Dense(len(tag2number))))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer ='rmsprop',\n",
    "                  metrics=['accuracy', ignore_pad_acc(0), accuracy(0), accuracy(1), accuracy(2), \n",
    "                          accuracy(3), accuracy(4), accuracy(5), accuracy(6), accuracy(7), accuracy(8), \n",
    "                          accuracy(9), accuracy(10), accuracy(11), accuracy(12), accuracy(13), accuracy(14), \n",
    "                          accuracy(15), accuracy(16), accuracy(17), accuracy(18), accuracy(19), accuracy(20), \n",
    "                          accuracy(21), accuracy(22), accuracy(23), accuracy(24), accuracy(25), accuracy(26), \n",
    "                          precision(0), precision(1), precision(2), precision(3), precision(4), precision(5), \n",
    "                          precision(6), precision(7), precision(8), precision(9), precision(10), precision(11),\n",
    "                          precision(12), precision(13), precision(14), precision(15), precision(16), \n",
    "                          precision(17), precision(18), precision(19), precision(20), precision(21), \n",
    "                          precision(22), precision(23), precision(24), precision(25), precision(26)])\n",
    "    #                       recall(1), recall(2),\n",
    "    #                       recall(3), recall(4), recall(5), recall(6), recall(7), \n",
    "    #                       recall(8), recall(9), recall(10), recall(11), recall(12),\n",
    "    #                       recall(13), recall(14), recall(15), recall(16), recall(17), \n",
    "    #                       recall(18), recall(19), recall(20), recall(21), recall(22),\n",
    "    #                       recall(23), recall(24), recall(25), recall(26)])\n",
    " \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_key_from_value(d, val):\n",
    "    return [k for k, v in d.items() if v == val]\n",
    "\n",
    "def save_results(scores, batch_size, epochs):\n",
    "    \n",
    "    if not os.path.exists('results/'):\n",
    "        os.makedirs('results/')\n",
    "    \n",
    "    with open('results/geral_acc_'+str(batch_size)+'_'+str(epochs)+'.csv', 'w') as f:\n",
    "        f.write('batch_size,epochs,loss,acc\\n')\n",
    "        f.write(str(batch_size)+','+str(epochs)+','+str(scores[0]+','+str(scores[2])+'\\n'))\n",
    "\n",
    "    with open('results/acc_class_'+str(batch_size)+'_'+str(epochs)+'.csv', 'w') as f:\n",
    "        f.write('batch_size,epochs,tag,accuracy\\n')\n",
    "\n",
    "    with open('results/precision_class_'+str(batch_size)+'_'+str(epochs)+'.csv', 'w') as f:\n",
    "        f.write('batch_size,epochs,tag,precision\\n')\n",
    "\n",
    "    for i, s in enumerate(scores):    \n",
    "        if i > 2 and i < 30:\n",
    "            with open('results/acc_class.csv', 'a+') as f:\n",
    "                f.write(str(batch_size)+','+str(epochs)+','+str(get_key_from_value(tag2number, i-2-1)[0])+','+\n",
    "                        str(s)+'\\n')\n",
    "        if i >= 30:\n",
    "            with open('results/precision_class.csv', 'a+') as f:\n",
    "                f.write(str(batch_size)+','+str(epochs)+','+str(get_key_from_value(tag2number, i-29-1)[0])+\",\"+\n",
    "                        str(s)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    train_words, train_tags, word2number, tag2number = pre_processing(file_train, train=True)\n",
    "    train_X, train_Y = convert_to_numbers(train_words, train_tags, word2number, tag2number)\n",
    "\n",
    "    test_words, test_tags = pre_processing(file_test)\n",
    "    test_X, test_Y = convert_to_numbers(test_words, test_tags, word2number, tag2number)\n",
    "\n",
    "    val_words, val_tags = pre_processing(file_val)\n",
    "    val_X, val_Y = convert_to_numbers(val_words, val_tags, word2number, tag2number)\n",
    "    \n",
    "    print('Pre-Processing Done.')\n",
    "    \n",
    "    MAX_LENGTH = max(max(len(max(train_X, key=len)), len(max(val_X, key=len))), len(max(test_X, key=len)))\n",
    "    print('Max Length of sentences: {}'.format(MAX_LENGTH))\n",
    "    \n",
    "    train_X, train_Y = padding_sequences(train_X, train_Y, MAX_LENGTH, tag2number)\n",
    "    test_X, test_Y = padding_sequences(test_X, test_Y, MAX_LENGTH, tag2number)\n",
    "    val_X, val_Y = padding_sequences(val_X, val_Y, MAX_LENGTH, tag2number)\n",
    "    \n",
    "    print('Padding Done.')\n",
    "    \n",
    "    model = create_model(MAX_LENGTH, tag2number, word2number)\n",
    "    \n",
    "    batch_sizes = [64, 128, 256] # verificar\n",
    "    epochs = [1, 5, 10]\n",
    "    \n",
    "    for e in epochs:\n",
    "        for bs in batch_sizes:\n",
    "            model.fit(train_X, train_Y, verbose=1, batch_size=bs, epochs=e, validation_data=(val_X, val_Y))\n",
    "            scores = model.evaluate(test_X, test_Y)\n",
    "            save_results(scores, batch_size, epochs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-Processing Done.\n",
      "Max Length of sentences: 248\n",
      "Padding Done.\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 37948 samples, validate on 1997 samples\n",
      "Epoch 1/1\n",
      "37948/37948 [==============================] - 590s 16ms/step - loss: 0.1348 - acc: 0.9628 - ignore_accuracy: 0.5697 - class_accuracy: 0.9562 - class_accuracy_1: 0.9480 - class_accuracy_2: 0.9650 - class_accuracy_3: 0.9652 - class_accuracy_4: 0.9629 - class_accuracy_5: 0.9636 - class_accuracy_6: 0.9643 - class_accuracy_7: 0.9661 - class_accuracy_8: 0.9650 - class_accuracy_9: 0.9635 - class_accuracy_10: 0.9632 - class_accuracy_11: 0.9649 - class_accuracy_12: 0.9636 - class_accuracy_13: 0.9643 - class_accuracy_14: 0.9633 - class_accuracy_15: 0.9639 - class_accuracy_16: 0.9639 - class_accuracy_17: 0.9632 - class_accuracy_18: 0.9629 - class_accuracy_19: 0.9631 - class_accuracy_20: 0.9631 - class_accuracy_21: 0.9628 - class_accuracy_22: 0.9628 - class_accuracy_23: 0.9628 - class_accuracy_24: 0.9628 - class_accuracy_25: 0.9628 - class_accuracy_26: 0.9628 - class_precision: 0.9887 - class_precision_1: 0.5230 - class_precision_2: 0.5087 - class_precision_3: 0.6025 - class_precision_4: 0.3119 - class_precision_5: 0.4110 - class_precision_6: 0.5646 - class_precision_7: 0.4031 - class_precision_8: 0.7272 - class_precision_9: 0.4061 - class_precision_10: 0.3996 - class_precision_11: 0.3101 - class_precision_12: 0.5451 - class_precision_13: 0.5862 - class_precision_14: 0.3812 - class_precision_15: 0.3122 - class_precision_16: 0.4197 - class_precision_17: 0.4332 - class_precision_18: 0.1496 - class_precision_19: 0.3125 - class_precision_20: 0.2678 - class_precision_21: 0.0000e+00 - class_precision_22: 0.0506 - class_precision_23: 0.0000e+00 - class_precision_24: 0.0101 - class_precision_25: 0.0000e+00 - class_precision_26: 0.0000e+00 - val_loss: 0.0253 - val_acc: 0.9924 - val_ignore_accuracy: 0.9029 - val_class_accuracy: 0.9924 - val_class_accuracy_1: 0.9922 - val_class_accuracy_2: 0.9922 - val_class_accuracy_3: 0.9920 - val_class_accuracy_4: 0.9924 - val_class_accuracy_5: 0.9925 - val_class_accuracy_6: 0.9923 - val_class_accuracy_7: 0.9915 - val_class_accuracy_8: 0.9924 - val_class_accuracy_9: 0.9925 - val_class_accuracy_10: 0.9926 - val_class_accuracy_11: 0.9930 - val_class_accuracy_12: 0.9924 - val_class_accuracy_13: 0.9922 - val_class_accuracy_14: 0.9923 - val_class_accuracy_15: 0.9929 - val_class_accuracy_16: 0.9927 - val_class_accuracy_17: 0.9924 - val_class_accuracy_18: 0.9924 - val_class_accuracy_19: 0.9925 - val_class_accuracy_20: 0.9925 - val_class_accuracy_21: 0.9924 - val_class_accuracy_22: 0.9924 - val_class_accuracy_23: 0.9924 - val_class_accuracy_24: 0.9924 - val_class_accuracy_25: 0.9924 - val_class_accuracy_26: 0.9924 - val_class_precision: 1.0000 - val_class_precision_1: 0.9039 - val_class_precision_2: 0.9188 - val_class_precision_3: 0.9162 - val_class_precision_4: 0.9840 - val_class_precision_5: 0.8606 - val_class_precision_6: 0.9619 - val_class_precision_7: 0.7314 - val_class_precision_8: 0.9996 - val_class_precision_9: 0.9468 - val_class_precision_10: 0.8818 - val_class_precision_11: 0.8088 - val_class_precision_12: 0.9766 - val_class_precision_13: 0.9479 - val_class_precision_14: 0.6716 - val_class_precision_15: 0.7892 - val_class_precision_16: 0.8838 - val_class_precision_17: 0.9313 - val_class_precision_18: 1.0000 - val_class_precision_19: 0.9034 - val_class_precision_20: 0.8165 - val_class_precision_21: 0.0000e+00 - val_class_precision_22: 0.5513 - val_class_precision_23: 0.0000e+00 - val_class_precision_24: 0.2243 - val_class_precision_25: 0.0000e+00 - val_class_precision_26: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7feb38b10590>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_X, train_Y, batch_size=128, epochs=1, validation_data=(val_X, val_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9987/9987 [==============================] - 66s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(test_X, test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
